{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"genWordFrequencyDict.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOXGcsDJEhGFMUygBKV1s+W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rqd9nGAYk6Ei","executionInfo":{"status":"ok","timestamp":1621361503857,"user_tz":420,"elapsed":23821,"user":{"displayName":"Sameer Khanna","photoUrl":"","userId":"09619767261910075275"}},"outputId":"6b14702f-de74-48ba-d19a-f022fbfabbcf"},"source":["# this mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","FOLDERNAME = \"ConicalClassificationGithub\"\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","\n","%cd drive/My\\ Drive\n","%cd $FOLDERNAME"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/My Drive\n","/content/drive/My Drive/ConicalClassificationGithub\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uN-rh8eGlF04","executionInfo":{"status":"ok","timestamp":1621361503859,"user_tz":420,"elapsed":23819,"user":{"displayName":"Sameer Khanna","photoUrl":"","userId":"09619767261910075275"}}},"source":["import pandas as pd"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"5h6zIIMUlJNF","executionInfo":{"status":"ok","timestamp":1621361505017,"user_tz":420,"elapsed":24969,"user":{"displayName":"Sameer Khanna","photoUrl":"","userId":"09619767261910075275"}},"outputId":"7c33eeb9-e35e-42c5-de80-0825973d2dc0"},"source":["#https://www.kaggle.com/rtatman/english-word-frequency\n","data = pd.read_csv(\"unigram_freq.csv\").dropna()\n","data.head()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>the</td>\n","      <td>23135851162</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>of</td>\n","      <td>13151942776</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>and</td>\n","      <td>12997637966</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>to</td>\n","      <td>12136980858</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>a</td>\n","      <td>9081174698</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  word        count\n","0  the  23135851162\n","1   of  13151942776\n","2  and  12997637966\n","3   to  12136980858\n","4    a   9081174698"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HruN051TlbVV","executionInfo":{"status":"ok","timestamp":1621361505019,"user_tz":420,"elapsed":24966,"user":{"displayName":"Sameer Khanna","photoUrl":"","userId":"09619767261910075275"}},"outputId":"bcb3e417-375e-4b34-be4d-1b569415dd50"},"source":["sum_count = sum(data['count'])\n","print(f\"Total word count is {sum_count}\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Total word count is 588090082941\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"W2MZeU5Olmzl","executionInfo":{"status":"ok","timestamp":1621361505020,"user_tz":420,"elapsed":24961,"user":{"displayName":"Sameer Khanna","photoUrl":"","userId":"09619767261910075275"}},"outputId":"170593c2-aa17-4ba8-85a5-50da88962adc"},"source":["data[\"freq\"] = data['count']/sum_count\n","data.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>count</th>\n","      <th>freq</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>the</td>\n","      <td>23135851162</td>\n","      <td>0.039341</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>of</td>\n","      <td>13151942776</td>\n","      <td>0.022364</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>and</td>\n","      <td>12997637966</td>\n","      <td>0.022101</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>to</td>\n","      <td>12136980858</td>\n","      <td>0.020638</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>a</td>\n","      <td>9081174698</td>\n","      <td>0.015442</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  word        count      freq\n","0  the  23135851162  0.039341\n","1   of  13151942776  0.022364\n","2  and  12997637966  0.022101\n","3   to  12136980858  0.020638\n","4    a   9081174698  0.015442"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i9vrWOT8l7Vk","executionInfo":{"status":"ok","timestamp":1621361540766,"user_tz":420,"elapsed":60701,"user":{"displayName":"Sameer Khanna","photoUrl":"","userId":"09619767261910075275"}},"outputId":"d2d9b1ab-f6b7-4a3a-a946-a0c4aca1dfa0"},"source":["import nltk\n","nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","\n","#Lemmatize\n","lemmatizer = WordNetLemmatizer()\n","\n","freqDict = {}\n","for index, row in data.iterrows():\n","    word = row[\"word\"]\n","    freq = row[\"freq\"]\n","    lem_word = lemmatizer.lemmatize(word)\n","    #If there are multiple words, choose the largest freq\n","    if lem_word in freqDict:\n","        freqDict[lem_word] = max(freqDict[lem_word], freq)\n","    else:\n","        freqDict[lem_word] = freq"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gJykb44cme6_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621361590167,"user_tz":420,"elapsed":566,"user":{"displayName":"Sameer Khanna","photoUrl":"","userId":"09619767261910075275"}},"outputId":"dfbd809c-fbc9-40d2-9bb2-f0328d80bddc"},"source":["import pickle\n","pickle.dump(freqDict, open(\"word_freq_dict.pkl\",\"wb\"))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["True\n"],"name":"stdout"}]}]}
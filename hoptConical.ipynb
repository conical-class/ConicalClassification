{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hoptConical.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOhQTY9bwsgr8HTbx64nshB"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T_676RR0mni7","executionInfo":{"status":"ok","timestamp":1621382272615,"user_tz":420,"elapsed":1652,"user":{"displayName":"Sameer Khanna","photoUrl":"","userId":"09619767261910075275"}},"outputId":"029e5aa7-47c4-437c-ff74-4ff2658010e1"},"source":["# this mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","FOLDERNAME = \"ConicalClassificationGithub\"\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","\n","%cd drive/My\\ Drive\n","%cd $FOLDERNAME"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/My Drive\n","/content/drive/My Drive/ConicalClassificationGithub\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n-4ERSMjHiJN","executionInfo":{"status":"ok","timestamp":1621382274284,"user_tz":420,"elapsed":3315,"user":{"displayName":"Sameer Khanna","photoUrl":"","userId":"09619767261910075275"}}},"source":["from sklearn.datasets import load_files\n","import codecs as cs\n","from load_dataset import *\n","\n","X_train, y_train, X_valid, y_valid, X_test, y_test = load_and_split()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"iPesfR07Rdtd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621382274819,"user_tz":420,"elapsed":3847,"user":{"displayName":"Sameer Khanna","photoUrl":"","userId":"09619767261910075275"}},"outputId":"67c3eeaf-be34-4399-f01c-049f65656fc4"},"source":["from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_FAIL\n","from hyperopt.pyll import scope as ho_scope\n","from hyperopt.pyll.stochastic import sample as ho_sample\n","import traceback\n","import math\n","import pickle\n","from sklearn.metrics import balanced_accuracy_score\n","from conical import CorpusClassification\n","\n","def objective(args):\n","    try:\n","        argDict = args\n","        idfDict = argDict.pop(\"idf\")\n","        for key in idfDict:\n","            argDict[key] = idfDict[key]\n","        #Fit\n","        conical = CorpusClassification(args)\n","        conical.fit(X_train)\n","\n","        #Evaluate\n","        y_pred = conical.predict(X_valid)\n","        val = -balanced_accuracy_score(y_valid, y_pred)\n","\n","        if math.isnan(val) or val is None:\n","            return {'loss': float('inf'), 'status': STATUS_FAIL }\n","        return {'loss': val, 'status': STATUS_OK }\n","\n","    except Exception as e:\n","        return {'loss': float('inf'), 'status': STATUS_FAIL }\n","\n","# define a search space\n","space = {\n","    'remove_outliers': hp.choice('remove_outliers', [True, False]),\n","    'use_bns': hp.choice('use_bns', [True, False]),\n","    'final_norm': hp.choice('final_norm', ['l1', 'l2', 'max', None]),\n","    'norm': hp.choice('norm', ['l1', 'l2', None]),\n","    'sublinear_tf': hp.choice('sublinear_tf', [True, False]),\n","    'max_features': ho_scope.int(hp.quniform('max_features', 1, 10000, q=1)),\n","    'idf': hp.choice('idf', [\n","        {\n","            'use_idf': True,\n","            'smooth_idf': hp.choice('smooth_idf', [True, False]),\n","        },\n","        {\n","            'use_idf': False,\n","        }\n","    ])\n","}"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MX3haT38_Not","executionInfo":{"status":"ok","timestamp":1621382434362,"user_tz":420,"elapsed":163384,"user":{"displayName":"Sameer Khanna","photoUrl":"","userId":"09619767261910075275"}},"outputId":"21b43272-934c-48e1-d57e-f4032540c254"},"source":["_model = \"Conical_Demo\"\n","\n","def run_trials():\n","    trials_step = 1  # how many additional trials to do after loading saved trials. 1 = save after iteration\n","    max_trials = 20  # initial max_trials. put something small to not have to wait\n","    try:  # try to load an already saved trials object, and increase the max\n","        with open(f\"{_model}.hyperopt\", \"rb\") as f:\n","            trials = pickle.load(f)\n","            print(\"Found saved Trials! Loading...\")\n","            max_trials = len(trials.trials) + trials_step\n","            print(\"Rerunning from {} trials to {} (+{}) trials\".format(len(trials.trials), max_trials, trials_step))\n","\n","    except:  # create a new trials object and start searching\n","        trials = Trials()\n","\n","    best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=max_trials, trials=trials)\n","    print(\"Best:\", space_eval(space, best))\n","\n","    # save the trials object\n","    print(\"Saving...\")\n","    with open(f\"{_model}.hyperopt\", \"wb\") as f:\n","        pickle.dump(trials, f)\n","    print(\"...Done\")\n","\n","# Loop run_trials indefinitely and stop whenever you like\n","# For the paper, we stopped once we reached max_trials\n","run_trials()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["100%|██████████| 20/20 [02:39<00:00,  7.97s/it, best loss: -1.0]\n","Best: {'final_norm': 'l1', 'idf': {'smooth_idf': True, 'use_idf': True}, 'max_features': 8956, 'norm': 'l2', 'remove_outliers': False, 'sublinear_tf': True, 'use_bns': True}\n","Saving...\n","...Done\n"],"name":"stdout"}]}]}